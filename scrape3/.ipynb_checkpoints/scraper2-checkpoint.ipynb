{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import project\n",
    "import founder\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from project import get_project, get_rewards\n",
    "from founder import get_profile, get_bio\n",
    "from featurizer1 import featurize\n",
    "from pymongo import MongoClient\n",
    "import urllib2\n",
    "\n",
    "import multiprocessing\n",
    "import sys\n",
    "import threading\n",
    "from timeit import Timer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize MongoDB database and collection\n",
    "client = MongoClient()\n",
    "db = client['ksdb']\n",
    "collection = db['ksdata']\n",
    "\n",
    "# Load array of project_id, founder_id and urls\n",
    "\n",
    "df = pd.read_csv('id_url_list.csv', dtype=object, header=None)\n",
    "id_url_list = df.values\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def subsample(arr, p=1):\n",
    "    '''\n",
    "    Returns random subsample of 2D array. Default sample\n",
    "    size is 100.\n",
    "    '''\n",
    "    mask = np.random.choice([True, False], arr.shape[0],\n",
    "        p = [p, 1 - p])\n",
    "\n",
    "    sub = arr[mask]\n",
    "\n",
    "    return sub\n",
    "\n",
    "def id_generator(arr):\n",
    "    '''\n",
    "    Create new generator.\n",
    "    '''\n",
    "    return (x for x in arr)\n",
    "\n",
    "def extract(generator):\n",
    "    '''\n",
    "    Scrapes Kickstarter pages and parses features into\n",
    "    MongoDB database. This function calls the featurize\n",
    "    function from the featurizer module to insert data\n",
    "    into the MongoDB database.\n",
    "    '''\n",
    "    go = True\n",
    "    progress = 0\n",
    "    skipped = 0\n",
    "    failed = 0\n",
    "\n",
    "    while go:\n",
    "        block_size = random.randint(5, 10)\n",
    "        wait_time = random.randint(2, 4)\n",
    "        wait = False\n",
    "\n",
    "        print '\\n'\n",
    "        print 'Block size: {0}'.format(block_size)\n",
    "\n",
    "        for i in xrange(0, block_size):\n",
    "            project_id,founder_id, project_url, founder_url, rewards_url = (x for x in generator.next())\n",
    "\n",
    "            collection_check = set(db.ksdata.distinct('project_id', {}))\n",
    "            if project_id in collection_check:\n",
    "                    print \"Already scraped\"\n",
    "                    skipped += 1\n",
    "                    wait = False\n",
    "\n",
    "\n",
    "            else:\n",
    "                try:\n",
    "                    project_soup, project_url, status1 = get_project(project_url)\n",
    "\n",
    "                    founder_soup, founder_url, status2 = get_profile(founder_url)\n",
    "\n",
    "                    rewards_soup, rewards_url, status3 = get_rewards(rewards_url)\n",
    "\n",
    "                    if (status1 & status2 & status3) == 200:\n",
    "                        featurize(project_id, founder_id, project_url, founder_url, rewards_url, project_soup, founder_soup, rewards_soup, collection)\n",
    "\n",
    "                        progress += 1\n",
    "\n",
    "                        wait = True\n",
    "\n",
    "                except requests.ConnectionError:\n",
    "                    failed +=1\n",
    "\n",
    "        print '\\n'\n",
    "\n",
    "        print 'Scraped: {}'.format(progress)\n",
    "\n",
    "        print 'Skipped: {}'.format(skipped)\n",
    "        \n",
    "        print 'Failed: {}'.format(failed)\n",
    "\n",
    "        print 'Next block: {}s'.format(wait_time)\n",
    "\n",
    "        if wait:\n",
    "            time.sleep(wait_time)\n",
    "\n",
    "        else:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_rewards(url_rewards):\n",
    "#     content = requests.get(url_rewards).content\n",
    "#     soup = BeautifulSoup(content, 'html.parser')\n",
    "#     r = requests.get(url_rewards)\n",
    "#     status = r.status_code\n",
    "\n",
    "#     print '({0})'.format(status), url_rewards\n",
    "\n",
    "#     return soup, url_rewards, status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gen = id_generator(id_url_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# extract(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scrape_parallel_concurrent(pool_size):\n",
    "    \"\"\"\n",
    "    Uses multiple processes to make requests to scrape website.\n",
    "    :param pool_size: number of worker processes\n",
    "    \"\"\"\n",
    "    pool = multiprocessing.Pool(pool_size)\n",
    "\n",
    "    for project in id_url_list:\n",
    "        pool.map(pool_extract, project)\n",
    "        pool.close()\n",
    "        pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pool_extract(generator):\n",
    "    failed = 0\n",
    "    skipped = 0\n",
    "    \n",
    "    project_id,founder_id, project_url, founder_url, rewards_url = generator\n",
    "\n",
    "    collection_check = set(db.ksdata.distinct('project_id', {}))\n",
    "    if project_id in collection_check:\n",
    "            print \"Already scraped\"\n",
    "            skipped += 1\n",
    "    else:\n",
    "        try:\n",
    "            project_soup, project_url, status1 = get_project(project_url)\n",
    "\n",
    "            founder_soup, founder_url, status2 = get_profile(founder_url)\n",
    "\n",
    "            rewards_soup, rewards_url, status3 = get_rewards(rewards_url)\n",
    "\n",
    "            if (status1 & status2 & status3) == 200:\n",
    "                featurize(project_id, founder_id, project_url, founder_url, rewards_url, project_soup, founder_soup, rewards_soup, collection)\n",
    "\n",
    "                progress += 1\n",
    "\n",
    "                wait = True\n",
    "\n",
    "        except requests.ConnectionError:\n",
    "            failed +=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
