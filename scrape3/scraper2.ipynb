{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import project\n",
    "import founder\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from project import get_project, get_rewards\n",
    "from founder import get_profile, get_bio\n",
    "from featurizer1 import featurize\n",
    "from pymongo import MongoClient\n",
    "import urllib2\n",
    "\n",
    "import multiprocessing\n",
    "import sys\n",
    "import threading\n",
    "from timeit import Timer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize MongoDB database and collection\n",
    "client = MongoClient()\n",
    "db = client['ksdb']\n",
    "collection = db['ksdata']\n",
    "\n",
    "# Load array of project_id,founder_id, project_url, founder_url, rewards_url\n",
    "\n",
    "df = pd.read_csv('id_url_list.csv', dtype=object, header=None)\n",
    "id_url_list = df.values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to scrape Kickstarter website based on the provided id_url_list.csv\n",
    "def pool_extract(gen):\n",
    "    failed = 0\n",
    "    skipped = 0\n",
    "    progress = 0\n",
    "    \n",
    "    project_id,founder_id, project_url, founder_url, rewards_url = gen\n",
    "\n",
    "    collection_check = set(db.ksdata.distinct('project_id', {}))\n",
    "    if int(project_id) in collection_check:\n",
    "            print \"Already scraped\"\n",
    "            skipped += 1\n",
    "    else:\n",
    "        try:\n",
    "            project_soup, project_url, status1 = get_project(project_url)\n",
    "\n",
    "            founder_soup, founder_url, status2 = get_profile(founder_url)\n",
    "\n",
    "            rewards_soup, rewards_url, status3 = get_rewards(rewards_url)\n",
    "\n",
    "            if (status1 & status2 & status3) == 200:\n",
    "                featurize(project_id, founder_id, project_url, founder_url, rewards_url, project_soup, founder_soup, rewards_soup, collection)\n",
    "\n",
    "                progress += 1\n",
    "\n",
    "                wait = True\n",
    "\n",
    "        except requests.ConnectionError:\n",
    "            failed +=1\n",
    "    \n",
    "    print '\\n'\n",
    "\n",
    "    print 'Scraped: {}'.format(progress)\n",
    "\n",
    "    print 'Skipped: {}'.format(skipped)\n",
    "\n",
    "    print 'Failed: {}'.format(failed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pool = multiprocessing.Pool(3)\n",
    "pool.map(pool_extract, id_url_list)\n",
    "pool.close()\n",
    "pool.join()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
